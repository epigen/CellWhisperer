{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.style.use(snakemake.input.mpl_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_barplot(scores, metric, metrics_pretty_dict,output_path=None,palette=None,ax=None, legend=True):\n",
    "    \"\"\"Plot grouped barplots of scores across datasets.\"\"\"\n",
    "\n",
    "    if output_path is None and ax is None:\n",
    "        raise ValueError(\"Either output_path or ax must be provided\")\n",
    "    if output_path is not None and ax is not None:\n",
    "        raise ValueError(\"Only one of output_path or ax can be provided\")\n",
    "    \n",
    "    scores_longform = scores.reset_index().rename(columns={'index': 'Model'})\n",
    "    scores_longform = pd.melt(\n",
    "        scores_longform,\n",
    "        id_vars=['Model'],\n",
    "        value_vars=scores.columns,\n",
    "        var_name='Dataset',\n",
    "        value_name='Score'\n",
    "    )\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        ax= plt.gca()\n",
    "    else:\n",
    "        plt.sca(ax)\n",
    "    sns.barplot(\n",
    "        x='Dataset',\n",
    "        y='Score',\n",
    "        hue='Model',\n",
    "        data=scores_longform,\n",
    "        palette=sns.color_palette(\"Greys\", scores_longform['Model'].nunique()) if palette is None else palette,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # Add the performance values above the bars (rotated by 45 degrees)\n",
    "    for p in plt.gca().patches:\n",
    "        if p.get_width()==0:\n",
    "            continue\n",
    "        plt.annotate(\n",
    "            f' {p.get_height():.2f}',\n",
    "            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            rotation=90,\n",
    "            fontsize=6,\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "    #plt.title('Model Performance Across Datasets')\n",
    "    plt.ylabel(metrics_pretty_dict[metric])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    if legend:\n",
    "        plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    else:\n",
    "        plt.legend().remove()\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"\")\n",
    "    \n",
    "\n",
    "    if output_path is not None:\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_translation_dict = {\"auroc\":\"rocauc_macroAvg\",\n",
    "                            \"accuracy\":\"accuracy_macroAvg\",\n",
    "                            \"f1\":\"f1_macroAvg\"\n",
    "                            }\n",
    "metrics_pretty_dict = {\"auroc\":\"AUROC\", \n",
    "                        \"accuracy\":\"Accuracy\",\n",
    "                        \"f1\":\"F1 Score\"\n",
    "                        }\n",
    "\n",
    "datasets_pretty_dict = {\"tabula_sapiens\":\"Tabula Sapiens\", \n",
    "                        \"pancreas\":\"Pancreas\",\n",
    "                        \"immgen\":\"ImmGen\",\n",
    "                        \"aida\":\"AIDA\",\n",
    "                        \"tabula_sapiens_well_studied_celltypes\": \"Tabula Sapiens\\n(20 common cell types)\",\n",
    "                        }\n",
    "\n",
    "models_pretty_dict = {\"uce\":\"UCE\",\n",
    "                      \"geneformer\":\"Geneformer\",\n",
    "                      \"scgpt\":\"scGPT\",\n",
    "                      \"CellWhisperer\":\"CellWhisperer\",\n",
    "                      \"CellAssign\":\"CellAssign\",\n",
    "                      \"cellwhisperer_clip_v1\":\"CellWhisperer (Geneformer-based)\",\n",
    "                      \"cellwhisperer_clip_v2_scgpt\":\"CellWhisperer (scGPT-based)\",\n",
    "                      \"cellwhisperer_clip_v2_uce\":\"CellWhisperer (UCE-based)\",\n",
    "                      }\n",
    "\n",
    "training_options_pretty_dict = {\"unfrozen\":\"unfrozen, with pseudo-bulking\",\n",
    "                                \"frozen_singlecells\":\"frozen, without pseudo-bulking\",\n",
    "                                \"frozen\":\"frozen, with pseudo-bulking\"}\n",
    "\n",
    "\n",
    "palette = {\n",
    "    # was: #A6CEE3, #1F78B4, #08306B\n",
    "    'UCE (unfrozen, with pseudo-bulking)':'#CAB2D6',  # light purple\n",
    "    'UCE (frozen, without pseudo-bulking)': '#6A3D9A',  # medium purple\n",
    "    'UCE (frozen, with pseudo-bulking)': '#3F007D',    # deep purple\n",
    "\n",
    "    \"CellAssign\": \"grey\",\n",
    "\n",
    "    # was: #B2DF8A, #33A02C, #006400\n",
    "    'scGPT (unfrozen, with pseudo-bulking)': '#CAB2D6',  # light purple\n",
    "    'scGPT (frozen, without pseudo-bulking)':'#6A3D9A',  # medium purple\n",
    "    'scGPT (frozen, with pseudo-bulking)': '#3F007D',    # deep purple\n",
    "\n",
    "    'Geneformer (unfrozen, with pseudo-bulking)': '#CAB2D6',  # light purple\n",
    "    'Geneformer (frozen, without pseudo-bulking)': '#6A3D9A',  # medium purple\n",
    "    'Geneformer (frozen, with pseudo-bulking)': '#3F007D',    # deep purple\n",
    "\n",
    "    \"CellWhisperer (Geneformer-based)\": '#ee9703', # orange, as for the cosine distance\n",
    "    \"CellWhisperer (scGPT-based)\": '#ee9703',# orange, as for the cosine distance\n",
    "    \"CellWhisperer (UCE-based)\": '#ee9703',# orange, as for the cosine distance\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_model_name_pretty = models_pretty_dict[snakemake.wildcards.model]\n",
    "\n",
    "fig, axes = plt.subplots(len(snakemake.params.metrics),1, figsize=(6,0.8*len(snakemake.params.metrics)), sharex=True)\n",
    "\n",
    "for i, metric in enumerate(snakemake.params.metrics):\n",
    "        \n",
    "    cw_scores = {} # For a given model and metric, this will contain the scores for all datasets\n",
    "    for label_col, dataset_macroavg_path, dataset_name in zip(snakemake.params.label_cols, snakemake.input.cw_macroaverages, snakemake.params.datasets):\n",
    "        assert label_col == \"celltype\", f\"Label column {label_col} is not supported. Only 'celltype' is allowed.\"\n",
    "        cw_macroavg_performance_df=pd.read_csv(dataset_macroavg_path, index_col=0)\n",
    "        cw_scores[dataset_name]=float(cw_macroavg_performance_df.loc[metrics_translation_dict[metric]].item().replace(\"tensor(\",\"\").replace(\")\",\"\"))\n",
    "    cw_df = pd.DataFrame.from_dict(cw_scores, orient='index', columns=[cw_model_name_pretty])\n",
    "\n",
    "    marker_based_method_scores = {}\n",
    "    for dataset, marker_based_method_performance in zip(snakemake.params.datasets, snakemake.input.marker_based_method_performances):\n",
    "        marker_based_method_scores[dataset] = pd.read_csv(marker_based_method_performance, index_col=0).loc[metric].item()\n",
    "    marker_based_method_df = pd.DataFrame.from_dict(marker_based_method_scores, orient='index', columns=['CellAssign'])\n",
    "\n",
    "    all_scores = []\n",
    "    for j, training_option in enumerate(snakemake.params.training_options):\n",
    "    \n",
    "        # Calculate the index in the flattened list\n",
    "        idx = i * len(snakemake.params.training_options) + j\n",
    "        aggregated_file = snakemake.input.aggregated_predictions_finetuned_models[idx]\n",
    "\n",
    "        assert metric in aggregated_file and training_option in aggregated_file, f\"Missing metric {metric} or training option {training_option} in {aggregated_file}\"\n",
    "\n",
    "        # Read the aggregated predictions for the current metric and training option\n",
    "        finetuned_scores = pd.read_csv(aggregated_file, index_col=0)\n",
    "\n",
    "        # Keep only rows that match the model_name\n",
    "        keep_rows = [x for x in finetuned_scores.index if x in cw_model_name_pretty.lower()]\n",
    "        finetuned_scores = finetuned_scores.loc[keep_rows]\n",
    "\n",
    "        # Merge the two dataframes on the index\n",
    "        if j==0:\n",
    "            scores = pd.merge(finetuned_scores.T, cw_df, left_index=True, right_index=True).T\n",
    "            scores = pd.merge(scores.T, marker_based_method_df, left_index=True, right_index=True).T\n",
    "            scores.index = [f\"{models_pretty_dict[rowname]} ({training_options_pretty_dict[training_option]})\" for rowname in scores.index[:-2]] + [cw_model_name_pretty, \"CellAssign\"]\n",
    "        else:\n",
    "            scores=finetuned_scores\n",
    "            scores.index = [f\"{models_pretty_dict[rowname]} ({training_options_pretty_dict[training_option]})\" for rowname in scores.index]\n",
    "        # Append the scores to the list\n",
    "        all_scores.append(scores)\n",
    "\n",
    "    # Concatenate all scores into a single DataFrame\n",
    "    all_scores_df = pd.concat(all_scores, axis=0)   \n",
    "    all_scores_df = all_scores_df.reindex(sorted(all_scores_df.index,reverse=True), axis=0) # nice ordering for plotting\n",
    "\n",
    "    all_scores_df.columns = [datasets_pretty_dict[col] for col in all_scores_df.columns]\n",
    "\n",
    "    # Also order the columns nicely\n",
    "    all_scores_df = all_scores_df.reindex(sorted(all_scores_df.columns, reverse=True), axis=1)\n",
    "\n",
    "    all_scores_df.to_csv(snakemake.output.scores_across_training_options[i], index=True, header=True)\n",
    "\n",
    "    # Plot the cross-training option plots:\n",
    "    plot_grouped_barplot(scores=all_scores_df,\n",
    "                         metric=metric, \n",
    "                         metrics_pretty_dict=metrics_pretty_dict,\n",
    "                         output_path=snakemake.output.barplots_across_training_options[i],\n",
    "                         palette=palette)\n",
    "\n",
    "    plot_grouped_barplot(scores=all_scores_df,\n",
    "                         metric=metric,\n",
    "                         metrics_pretty_dict=metrics_pretty_dict,\n",
    "                         output_path=None,\n",
    "                         palette=palette,ax=axes[i], legend=i==0)\n",
    "    \n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.subplots_adjust(hspace=0.65)\n",
    "plt.savefig(snakemake.output.barplots_across_training_options_across_metrics, bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
