{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40100a99",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import anndata\n",
    "import torchmetrics\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from zero_shot_validation_scripts.dataset_preparation import load_and_preprocess_dataset\n",
    "from finetuning_eval.models.geneformer import GeneformerCelltypeModel\n",
    "from cellwhisperer.jointemb.geneformer_model import (\n",
    "    GeneformerConfig,\n",
    "    GeneformerTranscriptomeProcessor,\n",
    ")\n",
    "from finetuning_eval.models.scgpt import ScGPTCelltypeModel, ScGPTConfig\n",
    "from finetuning_eval.models.uce import UCECelltypeModel, UCEConfig\n",
    "from cellwhisperer.jointemb.uce_model import UCETranscriptomeProcessor\n",
    "from cellwhisperer.jointemb.scgpt_model import ScGPTTranscriptomeProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_handle = open(snakemake.log.progress, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load data\n",
    "adata = load_and_preprocess_dataset(\n",
    "    dataset_name=snakemake.wildcards.dataset,\n",
    "    read_count_table_path=snakemake.input.eval_data,\n",
    ")\n",
    "\n",
    "#### Load transfered labels\n",
    "transfered_labels = pd.read_csv(snakemake.input.transfered_labels)\n",
    "transfered_labels\n",
    "\n",
    "assert set(transfered_labels.evaluation_cell_type.loc[lambda x: x != \"none\"]).issubset(\n",
    "    set(adata.obs[snakemake.params.label_col])\n",
    ")\n",
    "\n",
    "# It may happen that the celltypes annotated in CELLxGENE Census not fully cover all cell types in our evaluation datasets (e.g. Tabula Sapiens).\n",
    "# Sicne these celltypes cannot be predicted, we will exclude them from the evaluation\n",
    "uncovered_celltypes = set(adata.obs[snakemake.params.label_col]) - set(\n",
    "    transfered_labels.evaluation_cell_type.loc[lambda x: x != \"none\"]\n",
    ")\n",
    "\n",
    "if len(uncovered_celltypes) > 0:\n",
    "    adata = adata[~adata.obs[snakemake.params.label_col].isin(uncovered_celltypes)]\n",
    "    print(\n",
    "        \"Excluded the following cell types (as they cannot be predicted by the fine-tuned model): \"\n",
    "        + \", \".join(list(uncovered_celltypes))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7074dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_col = snakemake.params.label_col\n",
    "num_classes = len(adata.obs[label_col].unique())\n",
    "\n",
    "if snakemake.wildcards.model == \"geneformer\":\n",
    "    model = GeneformerCelltypeModel(\n",
    "        GeneformerConfig(), num_classes=len(transfered_labels)\n",
    "    )\n",
    "    transcriptome_processor = GeneformerTranscriptomeProcessor(\n",
    "        snakemake.threads, [\"natural_language_annotation\"]\n",
    "    )  # second argument is irrelevant\n",
    "elif snakemake.wildcards.model == \"scgpt\":\n",
    "    model = ScGPTCelltypeModel(ScGPTConfig(), num_classes=len(transfered_labels))\n",
    "    transcriptome_processor = ScGPTTranscriptomeProcessor(\n",
    "        snakemake.threads\n",
    "    )  # second argument is irrelevant\n",
    "elif snakemake.wildcards.model == \"uce\":\n",
    "    model = UCECelltypeModel(UCEConfig(), num_classes=len(transfered_labels))\n",
    "    transcriptome_processor = UCETranscriptomeProcessor(snakemake.threads)\n",
    "else:\n",
    "    raise NotImplementedError(f\"Model {snakemake.wildcards.model} not implemented\")\n",
    "\n",
    "model.load_state_dict(torch.load(snakemake.input.model))\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03aed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "batch_size = snakemake.params.batch_size\n",
    "predictions = []\n",
    "for i in tqdm(range(0, len(adata), batch_size)):\n",
    "    batch = adata[i : i + batch_size]\n",
    "\n",
    "    inputs = transcriptome_processor(batch, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {key: value.to(torch.device(\"cuda\")) for key, value in inputs.items()}\n",
    "    with torch.inference_mode():\n",
    "        predictions.append(model(**inputs).detach().cpu())\n",
    "\n",
    "    logfile_handle.write(f\"{i}/{len(adata)/batch_size}\\n\")\n",
    "    logfile_handle.flush()\n",
    "\n",
    "predictions = torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "predictions_raw_df = pd.DataFrame(\n",
    "    torch.softmax(predictions, 1).numpy(), columns=transfered_labels.training_cell_type\n",
    ")\n",
    "predictions_raw_df.index = adata.obs.index\n",
    "\n",
    "# create directory if it does not exist\n",
    "import os\n",
    "\n",
    "os.makedirs(os.path.dirname(snakemake.output.predictions_raw), exist_ok=True)\n",
    "\n",
    "predictions_raw_df.to_csv(snakemake.output.predictions_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the columns, according to the transfered labels\n",
    "\n",
    "predictions_df = pd.DataFrame(index=adata.obs.index)\n",
    "for evaluation_cell_type, training_cell_types in transfered_labels.groupby(\n",
    "    \"evaluation_cell_type\"\n",
    ")[\"training_cell_type\"]:\n",
    "    predictions_df[evaluation_cell_type] = predictions_raw_df[training_cell_types].sum(\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# sort the predictions:\n",
    "predictions_df=predictions_df[adata.obs[label_col].cat.categories]\n",
    "    \n",
    "\n",
    "predictions_df.to_csv(snakemake.output.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions using torchmetrics\n",
    "labels = torch.tensor(adata.obs[label_col].cat.codes.values)\n",
    "predictions = torch.tensor(predictions_df.values)\n",
    "\n",
    "accuracy = torchmetrics.functional.accuracy(\n",
    "    predictions,\n",
    "    labels,\n",
    "    average=\"macro\",\n",
    "    task=\"multiclass\",\n",
    "    num_classes=predictions_df.shape[1],\n",
    ")\n",
    "precision = torchmetrics.functional.precision(\n",
    "    predictions,\n",
    "    labels,\n",
    "    average=\"macro\",\n",
    "    task=\"multiclass\",\n",
    "    num_classes=predictions_df.shape[1],\n",
    ")\n",
    "recall = torchmetrics.functional.recall(\n",
    "    predictions,\n",
    "    labels,\n",
    "    average=\"macro\",\n",
    "    task=\"multiclass\",\n",
    "    num_classes=predictions_df.shape[1],\n",
    ")\n",
    "f1 = torchmetrics.functional.f1_score(\n",
    "    predictions,\n",
    "    labels,\n",
    "    average=\"macro\",\n",
    "    task=\"multiclass\",\n",
    "    num_classes=predictions_df.shape[1],\n",
    ")\n",
    "auroc = torchmetrics.functional.auroc(\n",
    "    torch.tensor(predictions_df.values),\n",
    "    labels,\n",
    "    task=\"multiclass\",\n",
    "    num_classes=predictions_df.shape[1],\n",
    ")\n",
    "\n",
    "performance = pd.Series(\n",
    "    {\n",
    "        \"accuracy\": accuracy.item(),\n",
    "        \"precision\": precision.item(),\n",
    "        \"recall\": recall.item(),\n",
    "        \"f1\": f1.item(),\n",
    "        \"auroc\": auroc.item(),\n",
    "    },\n",
    "    name=\"value\",\n",
    ")\n",
    "performance.index.name = \"metric\"\n",
    "performance.to_csv(snakemake.output.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_handle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
