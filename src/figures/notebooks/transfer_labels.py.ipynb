{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dbedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start coding here\n",
    "\n",
    "import openai\n",
    "import anndata\n",
    "import pandas as pd\n",
    "\n",
    "from zero_shot_validation_scripts.dataset_preparation import load_and_preprocess_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daabaf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adata = anndata.read_h5ad(snakemake.input.training_data, backed=\"r\")\n",
    "training_cell_types = train_adata.obs[\"cell_type\"].cat.categories\n",
    "\n",
    "eval_adata = load_and_preprocess_dataset(\n",
    "    dataset_name=snakemake.wildcards.dataset,\n",
    "    read_count_table_path=snakemake.input.eval_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b7136",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "prompt = f\"Assign the cell type '{{}}' to one of the following candidates: {', '.join(eval_adata.obs.celltype.drop_duplicates().values)}.\\n\\n If there is no well-matching cell type present, assign none instead. Only print the name of a single cell type (or none if none of the candidates match), nothing else.\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=snakemake.params.openai_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe25db",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for training_cell_type in training_cell_types:\n",
    "    if training_cell_type in eval_adata.obs.celltype.drop_duplicates().values:\n",
    "        print(\n",
    "            f\"Skipping {training_cell_type} as it is already present in the evaluation dataset\"\n",
    "        )\n",
    "        predictions.append(training_cell_type)\n",
    "        continue\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt.format(training_cell_type),\n",
    "            }\n",
    "        ],\n",
    "        model=snakemake.params.model,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    match = chat_completion.choices[0].message.content\n",
    "    if match not in eval_adata.obs.celltype.drop_duplicates().values:\n",
    "        print(\n",
    "            f\"Match for {training_cell_type} was not in the candidates ({match}). Set to 'none'\"\n",
    "        )\n",
    "        match = \"none\"\n",
    "    else:\n",
    "        print(f\"Match for {training_cell_type} was {match}\")\n",
    "\n",
    "    predictions.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c190da8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"training_cell_type\": training_cell_types, \"evaluation_cell_type\": predictions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_eval_celltypes = set(eval_adata.obs.celltype) - set(df.evaluation_cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df = df.copy()\n",
    "corrected_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_eval_celltypes = set(eval_adata.obs.celltype) - set(\n",
    "    corrected_df.evaluation_cell_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46e44d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for eval_celltype in missing_eval_celltypes:\n",
    "    # All training celltypes, except the ones that are assigned to exactly one evaluation_cell_type\n",
    "    single_eval_types = (\n",
    "        corrected_df[\"evaluation_cell_type\"].value_counts().loc[lambda x: x == 1].index\n",
    "    )\n",
    "    possible_celltypes = training_cell_types.difference(\n",
    "        corrected_df.set_index(\"evaluation_cell_type\")\n",
    "        .loc[single_eval_types, \"training_cell_type\"]\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    prompt = f\"Assign the query cell type '{{}}' to one of the following candidates: {', '.join(possible_celltypes)}.\\n\\n Only print the name of a single cell type, nothing else, and don't just repeat the query cell type. Make sure to return one of the candidates\"\n",
    "\n",
    "    for temperature in [0.0, 0.5, 0.8, 0.8, 0.8, 0.8, 1.1, 1.4]:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt.format(eval_celltype),\n",
    "                }\n",
    "            ],\n",
    "            model=snakemake.params.model,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        match = chat_completion.choices[0].message.content\n",
    "        if match not in possible_celltypes:\n",
    "            print(\n",
    "                f\"Failed to match for {eval_celltype} was not in the candidates ({match}). Set to 'none'\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Match for {eval_celltype} was {match}\")\n",
    "            corrected_df.loc[\n",
    "                corrected_df[\"training_cell_type\"] == match, \"evaluation_cell_type\"\n",
    "            ] = eval_celltype\n",
    "            break\n",
    "    else:\n",
    "        print(f\"no hope for {eval_celltype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df.evaluation_cell_type.loc[\n",
    "    lambda x: x != \"none\"\n",
    "]  # what does the loc do??? training_cell_type is never none..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df.to_csv(snakemake.output.transfered_labels, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
